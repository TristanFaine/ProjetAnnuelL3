# ProjetAnnuelL3

## Avant de réaliser ce projet, certains prototypes de crawlers ont été produits : vous pouvez les trouver dans crawlers_standalonz

#Ce projet est divisé en 2 parties :

## 1. Rendre disponible une API simple d'architecture REST pour insérer, modifier, effacer des données. Cela peut se faire en utilisant le format JSON par exemple.

## 2. Produire une interface permettant de piloter des crawlers, et d'interagir avec l'API, celle-ci est faite en PHP, il est donc possible d'utiliser celle-ci en local en utilisant le serveur web interne proposé : php -S localhost:8000.
## Il est également possible d'utiliser cette interface à distance vu que c'est une application Web, par exemple en intranet.


# Historique des étapes de développement :
## 1.  Localiser des sources de dialogues sur Internet
## 2.  Les récupérer, par des techniques plus ou moins automatiques (MechanicalSoup, Scrapy, Selenium)
## 3.  Trouver une logique pour les organiser au sein d'une base de données, et d'avoir une interface pour exploiter différentes techniques
## 4. Mettre en place un manager de crawler (Interface PHP)
## 5. Mettre en place la base de données.
## 6. Vérifier que tout fonctionne a distance.
## 7. Améliorer l'architecture de la page PHP, ajouter de nouveaux crawlers, proposer un systéme d'administration.


